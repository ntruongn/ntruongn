# Danh sách bài báo bảo mật ML/DL tại NDSS 2024

| Tên bài báo | Link tải | Tóm tắt |
| --- | --- | --- |
| **Diffence: Fencing Membership Privacy With Diffusion Models** | [Link tải](https://dx.doi.org/10.14722/ndss.2024.diffence) | Bài báo đề xuất một phương pháp bảo vệ thông tin thành viên trong dữ liệu huấn luyện của mô hình diffusion. Bằng cách sử dụng các kỹ thuật diffusion, tác giả giảm thiểu khả năng tấn công membership inference mà không làm giảm hiệu năng của mô hình. |
| **DorPatch: Distributed and Occlusion-Robust Adversarial Patch to Evade Certifiable Defenses** | [Link tải](https://dx.doi.org/10.14722/ndss.2024.dorpatch) | Nghiên cứu giới thiệu một kỹ thuật tấn công bằng adversarial patch có khả năng phân phối và chịu được hiệu ứng che khuất. Phương pháp này có thể vượt qua các hệ thống phòng thủ đã được chứng nhận về độ bền vững. |
| **Group-based Robustness: A General Framework for Customized Robustness in the Real World** | [Link tải](https://dx.doi.org/10.14722/ndss.2024.grouprobust) | Bài báo đưa ra khung đo lường và tăng cường khả năng chịu đựng của các mô hình ML đối với các cuộc tấn công adversarial. Thông qua việc nhóm các mẫu dữ liệu theo đặc trưng, phương pháp này cho phép điều chỉnh mức độ robust theo từng trường hợp cụ thể trong môi trường thực tế. |
| **Automatic Adversarial Adaption for Stealthy Poisoning Attacks in Federated Learning** | [Link tải](https://dx.doi.org/10.14722/ndss.2024.autoattack) | Nghiên cứu trình bày một phương pháp tấn công poisoning trong federated learning có khả năng tự động thích ứng. Kỹ thuật này làm tăng độ “ẩn” của cuộc tấn công, gây khó khăn cho việc phát hiện và phòng chống trong các hệ thống học tập phân tán. |
| **Membership Inference Attacks Against In-Context Learning** | [Link tải](https://dx.doi.org/10.14722/ndss.2024.miic) | Bài báo khảo sát nguy cơ rò rỉ thông tin thông qua các cuộc tấn công membership inference trong bối cảnh in-context learning của các mô hình LLM. Nghiên cứu chỉ ra rằng ngay cả khi các mô hình được sử dụng theo phương thức “in-context”, thông tin về dữ liệu huấn luyện vẫn có thể bị lộ ra. |


# Danh sách bài báo bảo mật ML/DL tại NDSS 2025

| Tên bài báo | Link tải | Tóm tắt |
| --- | --- | --- |
| **Understanding Data Importance in Machine Learning Attacks: Does Valuable Data Pose Greater Harm?** | [Link tải](https://dx.doi.org/10.14722/ndss.2025.230331) | Nghiên cứu phân tích vai trò của các mẫu dữ liệu "quan trọng" trong hiệu suất của các cuộc tấn công ML (như membership inference, model stealing). Kết quả chỉ ra rằng các dữ liệu có giá trị cao dễ bị tấn công hơn. |
| **ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models** | [Link tải](https://www.ndss-symposium.org/ndss-paper/ml-leaks-model-and-data-independent-membership-inference-attacks-and-defenses-on-machine-learning-models/) | Bài báo mở rộng khả năng của các cuộc tấn công membership inference bằng cách loại bỏ các giả định ban đầu (ví dụ: yêu cầu shadow models hay kiến trúc mô hình cố định) và đề xuất các giải pháp phòng thủ hiệu quả. |
| **SIGuard: Guarding Secure Inference with Post Data Privacy** | [Link tải](https://www.ndss-symposium.org/ndss-paper/siguard-guarding-secure-inference-with-post-data-privacy/) | SIGuard đề xuất một framework bảo vệ kết quả dự đoán của các mô hình secure inference bằng cách thêm nhiễu một cách có kiểm soát, giúp giảm thiểu rủi ro tấn công membership inference mà vẫn đảm bảo độ chính xác. |
| **ASGARD: Protecting On-Device Deep Neural Networks with Virtualization-Based Trusted Execution Environments** | [Link tải](https://www.ndss-symposium.org/ndss-paper/asgard-protecting-on-device-deep-neural-networks-with-virtualization-based-trusted-execution-environments/) | ASGARD sử dụng Trusted Execution Environments (TEE) dựa trên ảo hóa để bảo vệ các mô hình DNN chạy trên thiết bị, đảm bảo TCB nhỏ và hiệu năng cao mà không cần thay đổi phần mềm proprietary. |
| **BumbleBee: Secure Two-party Inference Framework for Large Transformers** | [Link tải](https://www.ndss-symposium.org/ndss-paper/bumblebee-secure-two-party-inference-framework-for-large-transformers/) | Bài báo giới thiệu một framework cho phép thực hiện inference an toàn giữa hai bên với các mô hình Transformer quy mô lớn, đảm bảo bảo mật và riêng tư của dữ liệu trong quá trình tính toán. |
| **Black-box Membership Inference Attacks against Fine-tuned Diffusion Models** | [Link tải](https://www.ndss-symposium.org/ndss-paper/black-box-membership-inference-attacks-against-fine-tuned-diffusion-models/) | Nghiên cứu chứng minh các cuộc tấn công membership inference vẫn hiệu quả trên các mô hình diffusion đã được fine-tune, mở ra góc nhìn về các lỗ hổng bảo mật mới trong các hệ thống DL tiên tiến. |
| **Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning** | [Link tải](https://www.ndss-symposium.org/ndss-paper/scale-mia-a-scalable-model-inversion-attack-against-secure-federated-learning/) | Scale-MIA đề xuất một phương pháp tấn công model inversion mở rộng, nhắm vào hệ thống federated learning, cho thấy khả năng lộ lọt thông tin đào tạo mà không cần nhiều giả định ban đầu. |
| **MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots** | [Link tải](https://www.ndss-symposium.org/ndss-paper/masterkey-automated-jailbreaking-of-large-language-model-chatbots/) | MASTERKEY tự động khai thác lỗ hổng bảo mật trong các chatbot dựa trên LLM, cho phép "jailbreak" các dịch vụ dựa trên mô hình ngôn ngữ lớn một cách hiệu quả và tiết kiệm chi phí. |
| **Legilimens: Practical and Unified Content Moderation for Large Language Model Services** | [Link tải](https://www.ndss-symposium.org/ndss-paper/legilimens-practical-and-unified-content-moderation-for-large-language-model-services/) | Legilimens cung cấp giải pháp kiểm soát nội dung thống nhất cho các dịch vụ LLM, nhằm giảm thiểu rủi ro liên quan đến việc phát tán nội dung độc hại hay không phù hợp. |
| **Raconteur: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer** | [Link tải](https://www.ndss-symposium.org/ndss-paper/raconteur-a-knowledgeable-insightful-and-portable-llm-powered-shell-command-explainer/) | Raconteur sử dụng các mô hình LLM để giải thích các lệnh shell, hỗ trợ phân tích mã nguồn và phát hiện các hành vi bất thường trong hệ thống một cách hiệu quả. |

